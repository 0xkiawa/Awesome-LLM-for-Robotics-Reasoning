Category,Subcategory,Models,ArXiv Link,Title,Publication Date
LLM,Open sourced LLM,BERT,https://arxiv.org/abs/1810.04805,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,11 Oct 2018
LLM,Open sourced LLM,T5,https://arxiv.org/abs/1910.10683,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer,23 Oct 2019
LLM,Open sourced LLM,LLaMA,https://arxiv.org/abs/2302.13971,LLaMA: Open and Efficient Foundation Language Models,27 Feb 2023
LLM,Open sourced LLM,OpenFlamingo,https://arxiv.org/abs/2308.01390,OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models,2 Aug 2023
LLM,Open sourced LLM,InstructBLIP,https://arxiv.org/abs/2305.06500,InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning,11 May 2023
LLM,Open sourced LLM,ChatBridge,https://arxiv.org/abs/2305.16103,ChatBridge: Bridging Modalities with Large Language Model as a Language Catalyst,25 May 2023
LLM,Closed sourced LLM,GPT3,https://arxiv.org/abs/2005.14165,Language Models are Few-Shot Learners,28 May 2020
LLM,Closed sourced LLM,GPT4,https://arxiv.org/abs/2303.08774,GPT-4 Technical Report,15 Mar 2023
LLM,Instruction Turning,InstructGPT,https://arxiv.org/abs/2203.02155,Training language models to follow instructions with human feedback,4 Mar 2022
LLM,Instruction Turning,LLaVA,https://arxiv.org/abs/2304.08485,Visual Instruction Tuning,17 Apr 2023
LLM,Instruction Turning,LLaVA,https://arxiv.org/abs/2304.08485,Visual Instruction Tuning,17 Apr 2023
LLM,Instruction Turning,MiniGPT-4,https://arxiv.org/abs/2304.10592,MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models,20 Apr 2023
LLM,Instruction Turning,FLAN,https://arxiv.org/abs/2109.01652,Finetuned Language Models Are Zero-Shot Learners,3 Sep 2021
LLM,Instruction Turning,LLaMA-adapter,https://arxiv.org/abs/2303.16199,LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention,28 Mar 2023
LLM,Instruction Turning,Self-Instruct,https://arxiv.org/abs/2212.10560,Self-Instruct: Aligning Language Models with Self-Generated Instructions,20 Dec 2022
LLM,Vision-LLM,LLaVA,https://arxiv.org/abs/2304.08485,Visual Instruction Tuning,17 Apr 2023
LLM,Vision-LLM,LLaVA,https://arxiv.org/abs/2304.08485,Visual Instruction Tuning,17 Apr 2023
LLM,Vision-LLM,GPT4-V OpenFlamingo,https://arxiv.org/abs/2308.01390,OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models,2 Aug 2023
LLM,Vision-LLM,InternGPT,https://arxiv.org/abs/2305.05662,InternGPT: Solving Vision-Centric Tasks by Interacting with ChatGPT Beyond Language,9 May 2023
LLM,Vision-LLM,PaLM,https://arxiv.org/abs/2204.02311,PaLM: Scaling Language Modeling with Pathways,5 Apr 2022
LLM,Spatial Understanding,Gpt-driver,https://arxiv.org/abs/2310.01415,GPT-Driver: Learning to Drive with GPT,2 Oct 2023
LLM,Spatial Understanding,Path planners,https://arxiv.org/abs/2310.03249,Can Large Language Models be Good Path Planners? A Benchmark and Investigation on Spatial-temporal Reasoning,5 Oct 2023
LLM,Visual Question Answering,CogVLM,https://arxiv.org/abs/2311.03079,CogVLM: Visual Expert for Pretrained Language Models,6 Nov 2023
LLM,Visual Question Answering,ViperGPT,https://arxiv.org/abs/2303.08128,ViperGPT: Visual Inference via Python Execution for Reasoning,14 Mar 2023
LLM,Visual Question Answering,VISPROG,https://arxiv.org/abs/2211.11559,Visual Programming: Compositional visual reasoning without training,18 Nov 2022
LLM,Visual Question Answering,MM-ReAct,https://arxiv.org/abs/2303.11381,MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action,20 Mar 2023
LLM,Visual Question Answering,Chameleon,https://arxiv.org/abs/2304.09842,Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models,19 Apr 2023
LLM,Visual Question Answering,Caption Anything,https://arxiv.org/abs/2305.02677,Caption Anything: Interactive Image Description with Diverse Multimodal Controls,4 May 2023
LLM,Temporal Logics,NL2TL,https://arxiv.org/abs/2305.07766,NL2TL: Transforming Natural Languages to Temporal Logics using Large Language Models,12 May 2023
LLM,Quantitive Analysis,GPT4Vis,https://arxiv.org/abs/2311.15732,GPT4Vis: What Can GPT-4 Do for Zero-shot Visual Recognition?,27 Nov 2023
LLM,Quantitive Analysis,Gemini vs GPT-4V,https://arxiv.org/abs/2312.15011,Gemini vs GPT-4V: A Preliminary Comparison and Combination of Vision-Language Models Through Qualitative Cases,22 Dec 2023
LLM,Survey Papers,A Survey of Large Language Models,https://arxiv.org/abs/2303.18223,A Survey of Large Language Models,31 Mar 2023
In-Context Learning,Chain of Thought,Chain of Thought,https://arxiv.org/abs/2201.11903,Chain-of-Thought Prompting Elicits Reasoning in Large Language Models,28 Jan 2022
In-Context Learning,Chain of Thought,Tree of Thought,https://arxiv.org/abs/2305.10601,Tree of Thoughts: Deliberate Problem Solving with Large Language Models,17 May 2023
In-Context Learning,Chain of Thought,Multimodal-CoT,https://arxiv.org/abs/2302.00923,Multimodal Chain-of-Thought Reasoning in Language Models,2 Feb 2023
In-Context Learning,Chain of Thought,Auto-CoT,https://arxiv.org/abs/2210.03493,Automatic Chain of Thought Prompting in Large Language Models,7 Oct 2022
In-Context Learning,Chain of Thought,Verify-and-Edit,https://arxiv.org/abs/2305.03268,Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework,5 May 2023
In-Context Learning,Chain of Thought,Skeleton-of-Thought,https://arxiv.org/abs/2307.15337,Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding,28 Jul 2023
In-Context Learning,Chain of Thought,Rethinking with Retrieval,https://arxiv.org/abs/2301.00303,Rethinking with Retrieval: Faithful Large Language Model Inference,31 Dec 2022
In-Context Learning,Reasoning,Self-Consistency,https://arxiv.org/abs/2203.11171,Self-Consistency Improves Chain of Thought Reasoning in Language Models,21 Mar 2022
In-Context Learning,Reasoning,ReAct,https://arxiv.org/abs/2303.11366,ReAct: Synergizing Reasoning and Acting in Language Models,20 Mar 2023
In-Context Learning,Reasoning,Self-Refine,https://arxiv.org/abs/2303.17651,Self-Refine: Iterative Refinement with Self-Feedback,30 Mar 2023
In-Context Learning,Reasoning,Plan-and-Solve,https://arxiv.org/abs/2305.04091,Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models,6 May 2023
In-Context Learning,Reasoning,PAL,https://arxiv.org/abs/2211.10435,PAL: Program-aided Language Models,18 Nov 2022
In-Context Learning,Reasoning,Reasoning via Planning,https://arxiv.org/abs/2305.14992,Reasoning with Language Model is Planning with World Model,24 May 2023
In-Context Learning,Reasoning,Self-Ask,https://arxiv.org/abs/2210.03350,Measuring and Narrowing the Compositionality Gap in Language Models,7 Oct 2022
In-Context Learning,Reasoning,Least-to-Most Prompting,https://arxiv.org/abs/2205.10625,Least-to-Most Prompting Enables Complex Reasoning in Large Language Models,21 May 2022
In-Context Learning,Reasoning,Self-Polish,https://arxiv.org/abs/2305.14497,Self-Polish: Enhance Reasoning in Large Language Models via Problem Refinement,23 May 2023
In-Context Learning,Reasoning,COMPLEXITY-CoT,https://arxiv.org/abs/2210.00720,Complexity-Based Prompting for Multi-Step Reasoning,3 Oct 2022
In-Context Learning,Reasoning,SuperICL,https://arxiv.org/abs/2305.08848,Small Models are Valuable Plug-ins for Large Language Models,15 May 2023
In-Context Learning,Reasoning,VisualCOMET,https://arxiv.org/abs/2004.10796,VisualCOMET: Reasoning about the Dynamic Context of a Still Image,22 Apr 2020
In-Context Learning,Memory,MemoryBank,https://arxiv.org/abs/2305.10250,MemoryBank: Enhancing Large Language Models with Long-Term Memory,17 May 2023
In-Context Learning,Memory,ChatEval,https://arxiv.org/abs/2308.07201,ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate,14 Aug 2023
In-Context Learning,Memory,Generative Agents,https://arxiv.org/abs/2304.03442,Generative Agents: Interactive Simulacra of Human Behavior,7 Apr 2023
In-Context Learning,Planning,SelfCheck,https://arxiv.org/abs/2308.00436,SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning,1 Aug 2023
In-Context Learning,Automation,APE,https://arxiv.org/abs/2211.01910,Large Language Models Are Human-Level Prompt Engineers,3 Nov 2022
In-Context Learning,Self-supervised,Self-supervised ICL,https://arxiv.org/abs/2307.07742,SINC: Self-Supervised In-Context Learning for Vision-Language Tasks,15 Jul 2023
In-Context Learning,Benchmark,BIG-Bench,https://arxiv.org/abs/2206.04615,Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models,9 Jun 2022
In-Context Learning,Benchmark,ARB,https://arxiv.org/abs/2307.13692,ARB: Advanced Reasoning Benchmark for Large Language Models,25 Jul 2023
In-Context Learning,Benchmark,PlanBench,https://arxiv.org/abs/2206.10498,PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change,21 Jun 2022
In-Context Learning,Benchmark,Chain-of-Thought Hub,https://arxiv.org/abs/2305.17306,Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance,26 May 2023
In-Context Learning,Survey Paper,A Survey of Chain of Thought Reasoning,https://arxiv.org/abs/2309.15402,"A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future",27 Sep 2023
In-Context Learning,Survey Paper,Reasoning in Large Language Models,https://arxiv.org/abs/2212.10403,Towards Reasoning in Large Language Models: A Survey,20 Dec 2022
LLM for Agent,Planning,Voyager,https://arxiv.org/abs/2305.16291,Voyager: An Open-Ended Embodied Agent with Large Language Models,25 May 2023
LLM for Agent,Planning,DEPS,https://arxiv.org/abs/2302.01560,"Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents",3 Feb 2023
LLM for Agent,Planning,JARVIS-1,https://arxiv.org/abs/2311.05997,JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models,10 Nov 2023
LLM for Agent,Planning,LLM+P,https://arxiv.org/abs/2304.11477,LLM+P: Empowering Large Language Models with Optimal Planning Proficiency,22 Apr 2023
LLM for Agent,Planning,Autonomous Agents,https://arxiv.org/abs/2308.11432,A Survey on Large Language Model based Autonomous Agents,22 Aug 2023
LLM for Agent,Planning,AgentInstruct,https://arxiv.org/abs/2310.03710,Agent Instructs Large Language Models to be General Zero-Shot Reasoners,5 Oct 2023
LLM for Agent,Reinforcement Learning,Eureka,https://arxiv.org/abs/2310.12931,Eureka: Human-Level Reward Design via Coding Large Language Models,19 Oct 2023
LLM for Agent,Reinforcement Learning,Language to Rewards,https://arxiv.org/abs/2306.08647,Language to Rewards for Robotic Skill Synthesis,14 Jun 2023
LLM for Agent,Reinforcement Learning,Language Instructed Reinforcement Learning,https://arxiv.org/abs/2304.07297,Language Instructed Reinforcement Learning for Human-AI Coordination,13 Apr 2023
LLM for Agent,Reinforcement Learning,Lafite-RL,https://arxiv.org/abs/2311.02379,Accelerating Reinforcement Learning of Robotic Manipulations via Feedback from Large Language Models,4 Nov 2023
LLM for Agent,Reinforcement Learning,ELLM,https://arxiv.org/abs/2302.06692,Guiding Pretraining in Reinforcement Learning with Large Language Models,13 Feb 2023
LLM for Agent,Reinforcement Learning,RLAdapter,,RLAdapter: Bridging Large Language Models to Reinforcement Learning in Open Worlds,
LLM for Agent,Reinforcement Learning,AdaRefiner,https://arxiv.org/abs/2309.17176,AdaRefiner: Refining Decisions of Language Models with Adaptive Feedback,29 Sep 2023
LLM for Agent,Reinforcement Learning,Reward Design with Language Models,https://arxiv.org/abs/2303.00001,Reward Design with Language Models,27 Feb 2023
LLM for Agent,Reinforcement Learning,EAGER,https://arxiv.org/abs/2206.09674,EAGER: Asking and Answering Questions for Automatic Reward Shaping in Language-guided RL,20 Jun 2022
LLM for Agent,Reinforcement Learning,Text2Reward,https://arxiv.org/abs/2309.11489,Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning,20 Sep 2023
LLM for Agent,Open-Source Evaluation,AgentSims,https://arxiv.org/abs/2308.04026,AgentSims: An Open-Source Sandbox for Large Language Model Evaluation,8 Aug 2023
LLM for Agent,Survey Paper,Large Language Model Based Agents,https://arxiv.org/abs/2309.07864,The Rise and Potential of Large Language Model Based Agents: A Survey,14 Sep 2023
LLM for Robots,Multimodal prompts,VIMA,https://arxiv.org/abs/2210.03094,VIMA: General Robot Manipulation with Multimodal Prompts,6 Oct 2022
LLM for Robots,Multimodal prompts,Instruct2Act,https://arxiv.org/abs/2305.11176,Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions with Large Language Model,18 May 2023
LLM for Robots,Multimodal prompts,MOMA-Force,https://arxiv.org/abs/2308.03624,MOMA-Force: Visual-Force Imitation for Real-World Mobile Manipulation,7 Aug 2023
LLM for Robots,Multimodal LLM,PaLM-E,https://arxiv.org/abs/2303.03378,PaLM-E: An Embodied Multimodal Language Model,6 Mar 2023
LLM for Robots,Multimodal LLM,GATO,https://arxiv.org/abs/2205.06175,A Generalist Agent,12 May 2022
LLM for Robots,Multimodal LLM,Flamingo,https://arxiv.org/abs/2204.14198,Flamingo: a Visual Language Model for Few-Shot Learning,29 Apr 2022
LLM for Robots,Multimodal LLM,Physically Grounded Vision-Language Model,https://arxiv.org/abs/2309.02561,Physically Grounded Vision-Language Models for Robotic Manipulation,5 Sep 2023
LLM for Robots,Multimodal LLM,MOO,https://arxiv.org/abs/2303.00905,Open-World Object Manipulation using Pre-trained Vision-Language Models,2 Mar 2023
LLM for Robots,Code generation,Code as policies,https://arxiv.org/abs/2209.07753,Code as Policies: Language Model Programs for Embodied Control,16 Sep 2022
LLM for Robots,Code generation,Progprompt,https://arxiv.org/abs/2209.11302,ProgPrompt: Generating Situated Robot Task Plans using Large Language Models,22 Sep 2022
LLM for Robots,Code generation,Socratic,https://arxiv.org/abs/2204.00598,Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language,1 Apr 2022
LLM for Robots,Code generation,SMART-LLM,https://arxiv.org/abs/2309.10062,SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language Models,18 Sep 2023
LLM for Robots,Code generation,Statler,https://arxiv.org/abs/2306.17840,Statler: State-Maintaining Language Models for Embodied Reasoning,30 Jun 2023
LLM for Robots,Decomposing task,SayCan,https://arxiv.org/abs/2204.01691,"Do As I Can, Not As I Say: Grounding Language in Robotic Affordances",4 Apr 2022
LLM for Robots,Decomposing task,Language Models as Zero-Shot Planners,https://arxiv.org/abs/2201.07207,Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents,18 Jan 2022
LLM for Robots,Decomposing task,SayPlan,https://arxiv.org/abs/2307.06135,SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Robot Task Planning,12 Jul 2023
LLM for Robots,Decomposing task,DOREMI,https://arxiv.org/abs/2307.00329,DoReMi: Grounding Language Model by Detecting and Recovering from Plan-Execution Misalignment,1 Jul 2023
LLM for Robots,Low-level output,SayTap,https://arxiv.org/abs/2306.07580,SayTap: Language to Quadrupedal Locomotion,13 Jun 2023
LLM for Robots,Low-level output,Prompt a Robot to Walk,https://arxiv.org/abs/2309.09969,Prompt a Robot to Walk with Large Language Models,18 Sep 2023
LLM for Robots,Multimodal Data injection,3D-LLM,https://arxiv.org/abs/2307.12981,3D-LLM: Injecting the 3D World into Large Language Models,24 Jul 2023
LLM for Robots,Multimodal Data injection,LiDAR-LLM,https://arxiv.org/abs/2312.14074,LiDAR-LLM: Exploring the Potential of Large Language Models for 3D LiDAR Understanding,21 Dec 2023
LLM for Robots,Data generation,Gensim,https://arxiv.org/abs/2310.01361,GenSim: Generating Robotic Simulation Tasks via Large Language Models,2 Oct 2023
LLM for Robots,Data generation,RoboGen,https://arxiv.org/abs/2311.01455,RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation,2 Nov 2023
LLM for Robots,Planning,Embodied Task Planning,https://arxiv.org/abs/2307.01848,Embodied Task Planning with Large Language Models,4 Jul 2023
LLM for Robots,Self-improvement,REFLECT,https://arxiv.org/abs/2306.15724,REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction,27 Jun 2023
LLM for Robots,Self-improvement,Reflexion,https://arxiv.org/abs/2303.11366,Reflexion: Language Agents with Verbal Reinforcement Learning,20 Mar 2023
LLM for Robots,Chain of Thought,EmbodiedGPT,https://arxiv.org/abs/2305.15021,EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought,24 May 2023
LLM for Robots,Brain,Robotic Brain,https://arxiv.org/abs/2304.09349,LLM as A Robotic Brain: Unifying Egocentric Memory and Control,19 Apr 2023
LLM for Robots,Survey papers,Toward General-Purpose,https://arxiv.org/abs/2312.08782,Toward General-Purpose Robots via Foundation Models: A Survey and Meta-Analysis,14 Dec 2023
LLM for Robots,Survey papers,Language-conditioned,https://arxiv.org/abs/2312.10807,Language-conditioned Learning for Robotic Manipulation: A Survey,17 Dec 2023
LLM for Robots,Survey papers,Foundation Models,https://arxiv.org/abs/2312.07843,"Foundation Models in Robotics: Applications, Challenges, and the Future",13 Dec 2023
LLM for Robots,Survey papers,Robot Learning,https://arxiv.org/abs/2311.14379,Robot Learning in the Era of Foundation Models: A Survey,24 Nov 2023
LLM for Robots,Survey papers,The Development of LLMs,https://arxiv.org/abs/2311.00530,The Development of LLMs for Embodied Navigation,1 Nov 2023
Perception,Object Detection,OWL-ViT,https://arxiv.org/abs/2205.06230,Simple Open-Vocabulary Object Detection with Vision Transformers,12 May 2022
Perception,Object Detection,GLIP,https://arxiv.org/abs/2112.03857,Grounded Language-Image Pre-training,7 Dec 2021
Perception,Object Detection,Grounding DINO,https://arxiv.org/abs/2303.05499,Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection,9 Mar 2023
Perception,Object Detection,PointCLIP,https://arxiv.org/abs/2112.02413,PointCLIP: Point Cloud Understanding by CLIP,4 Dec 2021
Perception,Object Detection,Segment Anything,https://arxiv.org/abs/2304.02643,Segment Anything,5 Apr 2023
