

| Category            | Subcategory                   | Models and Papers                                                  | Link                                                      |
|----------------------|-------------------------------|--------------------------------------------------------------------|-----------------------------------------------------------|
|  LLM               | Open sourced LLM             | BERT                                                               | [devlin2019bert](https://arxiv.org/abs/1810.04805)        |
|                      |                               | T5                                                                 | [raffel2023exploring](https://arxiv.org/abs/1910.10683)   |
|                      |                               | LLaMA                                                              | [touvron2023llama](https://arxiv.org/abs/2302.13971)      |
|                      |   Closed sourced LLM          | GPT3                                                               | [brown2020language](https://arxiv.org/abs/2005.14165)     |
|                      |                               | GPT4                                                               | [openai2023gpt4](https://arxiv.org/abs/2303.08774)        |
|                      | Instruction Turning            | InstructGPT                                                        | [ouyang2022training](https://arxiv.org/abs/2203.02155)   |
|                      |                               | LLaVA                                                              | [liu2023visual](https://arxiv.org/abs/2304.08485)         |
|                      |                               | MiniGPT-4                                                          | [zhu2023minigpt4](https://arxiv.org/abs/2304.10592)       |
|                      |                               | FLAN                                                               | [wei2022finetuned](https://arxiv.org/abs/2109.01652)      |
|                      |                               | LLaMA-adapter                                                      | [zhang2023llamaadapter](https://arxiv.org/abs/2303.16199) |
|                      | Vision-LLM                    | LLaVA                                                              | [liu2023visual](https://arxiv.org/abs/2304.08485)         |
|                      |                               | GPT4-V OpenFlamingo                                                | [awadalla2023openflamingo](https://arxiv.org/abs/2308.01390)|
|                      |                               | InternGPT                                                          | [liu2023interngpt](https://arxiv.org/abs/2305.05662)      |
|                      |                               | PaLM                                                               | [chowdhery2022palm](https://arxiv.org/abs/2204.02311)     |
|                      | Spatial Understanding         | Gpt-driver                                                         | [mao2023gptdriver](https://arxiv.org/abs/2310.01415)      |
|                      |                               | Path planners                                                      | [aghzal2023large](https://arxiv.org/abs/2310.03249)       |
|                      | Visual Question Answering     | CogVLM                                                             | [wang2023cogvlm](https://arxiv.org/abs/2311.03079)        |
|                      |                               | ViperGPT                                                           | [sur√≠s2023vipergpt](https://arxiv.org/abs/2303.08128)     |
|                      |                               | VISPROG                                                            | [gupta2022visual](https://arxiv.org/abs/2211.11559)       |
|                      |                               | MM-ReAct                                                           | [yang2023mmreact](https://arxiv.org/abs/2303.11381)       |
|                      |                               | Chameleon                                                          | [lu2023chameleon](https://arxiv.org/abs/2304.09842)       |
|                      | Survey Papers                 | A Survey of Large Language Models                                  | [zhao2023survey](https://arxiv.org/abs/2303.18223)        |
| Incontext Learning   | Chain of Thought              | Chain of Thought                                                   | [wei2023chainofthought](https://arxiv.org/abs/2201.11903) |
|                      |                               | Multimodal-CoT                                                     | [zhang2023multimodal](https://arxiv.org/abs/2302.00923)   |
|                      |                               | Auto-CoT                                                           | [zhang2022automatic](https://arxiv.org/abs/2210.03493)    |
|                      | Reasoning                     | Self-Consistency                                                   | [wang2023selfconsistency](https://arxiv.org/abs/2203.11171)|
|                      |                               | Tree of Thought                                                    | [yao2023tree](https://arxiv.org/abs/2305.10601)           |
|                      |                               | ReAct                                                              | [yao2023react](https://arxiv.org/abs/2303.11366)          |
|                      |                               | Self-Refine                                                        | [madaan2023selfrefine](https://arxiv.org/abs/2303.17651)  |
|                      |                               | Plan-and-Solve                                                     | [wang2023planandsolve](https://arxiv.org/abs/2305.04091)  |
|                      |                               | PAL                                                                | [gao2023pal](https://arxiv.org/abs/2211.10435)            |
|                      |                               | Reasoning via Planning                                             | [hao2023reasoning](https://arxiv.org/abs/2305.14992)      |
|                      |                               | Self-Ask                                                           | [press2023measuring](https://arxiv.org/abs/2210.03350)    |
|                      |                               | Least-to-Most Prompting                                            | [zhou2023leasttomost](https://arxiv.org/abs/2205.10625)   |
|                      |                               | Self-Polish                                                        | [xi2023selfpolish](https://arxiv.org/abs/2305.14497)      |
|                      |                               | COMPLEXITY-CoT                                                     | [fu2023complexitybased](https://arxiv.org/abs/2210.00720) |
|                      |                               | SuperICL                                                           | [xu2023small](https://arxiv.org/abs/2305.08848)           |
|                      | Automation                    | APE                                                                | [zhou2023large](https://arxiv.org/abs/2211.01910)         |
| LLM for Agent        | Planning                      | Voyager                                                            | [wang2023voyager](https://arxiv.org/abs/2305.16291)       |
|                      |                               | DEPS                                                               | [wang2023describe](https://arxiv.org/abs/2302.01560)      |
|                      |                               | JARVIS-1                                                           | [wang2023jarvis1](https://arxiv.org/abs/2311.05997)       |
|                      | Reinforcement Learning        | Eureka                                                             | [ma2023eureka](https://arxiv.org/abs/2310.12931)          |
|                      |                               | Language to Rewards                                                | [yu2023language](https://arxiv.org/abs/2306.08647)        |
|                      |                               | Language Instructed Reinforcement Learning                         | [hu2023language](https://arxiv.org/abs/2304.07297)        |
|                      |                               | Lafite-RL                                                          | [chu2023accelerating](https://arxiv.org/abs/2311.02379)   |
|                      | Survey Paper                  | The Rise and Potential of Large Language Models                    | [xi2023rise](https://arxiv.org/abs/2309.07864)            |
|                      |                               | Autonomous Agents                                                  | [wang2023survey](https://arxiv.org/abs/2308.11432)        |
|  LLM for Robots                 | Multimodal prompts             | VIMA                                                      | [jiang2023vima](https://arxiv.org/abs/2210.03094)          |
|                                |                                | Instruct2Act                                         | [huang2023instruct2act](https://arxiv.org/abs/2305.11176)  |
|                                |                                | MOMA-Force                                                | [yang2023momaforce](https://arxiv.org/abs/2308.03624)      |
|                                | Multimodal LLM                 | PaLM-E                                                    | [driess2023palme](https://arxiv.org/abs/2303.03378)        |
|                                |                                | GATO                                                      | [reed2022generalist](https://arxiv.org/abs/2205.06175)     |
|                                |                                | Flamingo                                                  | [alayrac2022flamingo](https://arxiv.org/abs/2204.14198)    |
|                                |                                | Physically Grounded Vision-Language Model                | [gao2023physically](https://arxiv.org/abs/2309.02561)      |
|                                |                                | MOO                                                       | [stone2023openworld](https://arxiv.org/abs/2303.00905)     |
|                                | Code generation                | Code as policies                                          | [liang2023code](https://arxiv.org/abs/2209.07753)          |
|                                |                                | Progprompt                                                | [singh2022progprompt](https://arxiv.org/abs/2209.11302)    |
|                                |                                | Socratic                                                  | [zeng2022socratic](https://arxiv.org/abs/2204.00598)       |
|                                |                                | SMART-LLM                                                 | [kannan2023smartllm](https://arxiv.org/abs/2309.10062)     |
|                                |                                | Statler                                                   | [yoneda2023statler](https://arxiv.org/abs/2306.17840)      |
|                                | Decomposing task               | SayCan                                                    | [ahn2022i](https://arxiv.org/abs/2204.01691)               |
|                                |                                | Language Models as Zero-Shot Planners                     | [huang2022language](https://arxiv.org/abs/2201.07207)      |
|                                |                                | SayPlan                                                   | [rana2023sayplan](https://arxiv.org/abs/2307.06135)        |
|                                |                                | DOREMI                                                    | [guo2023doremi](https://arxiv.org/abs/2307.00329)          |
|                                | Low-level output               | SayTap                                                    | [tang2023saytap](https://arxiv.org/abs/2309.03623)         |
|                                |                                | Prompt a Robot to Walk                                    | [wang2023prompt](https://arxiv.org/abs/2310.03248)         |
|                                | Multimodal Data injection      | 3D-LLM                                                    | [hong20233dllm](https://arxiv.org/abs/2308.11323)          |
|                                |                                | LiDAR-LLM                                                 | [yang2023lidarllm](https://arxiv.org/abs/2310.04249)       |
|                                | Data generation                | Gensim                                                    | [wang2023gensim](https://arxiv.org/abs/2307.01234)         |
|                                | Planning                       | Embodied Task Planning                                    | [wu2023embodied](https://arxiv.org/abs/2306.08127)         |
|                                | Self-improvement               | REFLECT                                                   | [liu2023reflect](https://arxiv.org/abs/2310.07654)         |
|                                |                                | Reflexion                                                 | [shinn2023reflexion](https://arxiv.org/abs/2309.10432)     |
|                                | Chain of Thought               | EmbodiedGPT                                               | [mu2023embodiedgpt](https://arxiv.org/abs/2308.05123)      |
|                                | Survey papers                  | Toward General-Purpose                                    | [hu2023generalpurpose](https://arxiv.org/abs/2305.11432)   |
|                                |                                | Language-conditioned                               | [zhou2023languageconditioned](https://arxiv.org/abs/2306.09876)|
|                                |                                | Foundation Models                                  | [firoozi2023foundation](https://arxiv.org/abs/2310.09987)  |
|                                |                                | Robot Learning                                            | [xiao2023robot](https://arxiv.org/abs/2309.11234)          |
|                                |                                | The Development of LLMs                                   | [lin2023development](https://arxiv.org/abs/2308.06789)     |
