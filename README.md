# Awesome-LLM-VLM-Brain
Awesome-LLM-VLM-Brain

| Category            | Subcategory                   | Models and Papers                                                      |
|----------------------|-------------------------------|------------------------------------------------------------------------|
| Our Investigation    | LLM                           | - Open sourced LLM                                                     |
|                      |                               |   - BERT\cite{devlin2019bert}                                           |
|                      |                               |   - T5\cite{raffel2023exploring}                                        |
|                      |                               |   - LLaMA\cite{touvron2023llama}                                       |
|                      |                               | - Closed sourced LLM                                                   |
|                      |                               |   - GPT3\cite{brown2020language}                                        |
|                      |                               |   - GPT4\cite{openai2023gpt4}                                          |
|                      | Instruction Turning            | - InstructGPT\cite{ouyang2022training}                                 |
|                      |                               | - LLaVA\cite{liu2023visual}                                            |
|                      |                               | - MiniGPT-4\cite{zhu2023minigpt4}                                      |
|                      |                               | - FLAN\cite{wei2022finetuned}                                          |
|                      |                               | - LLaMA-adapter\cite{zhang2023llamaadapter}                            |
|                      | Vision-LLM                    | - LLaVA\cite{liu2023visual}                                            |
|                      |                               | - GPT4-V OpenFlamingo\cite{awadalla2023openflamingo}                     |
|                      |                               | - InternGPT\cite{liu2023interngpt}                                      |
|                      |                               | - PaLM\cite{chowdhery2022palm}                                         |
|                      | Spatial Understanding         | - Gpt-driver\cite{mao2023gptdriver}                                    |
|                      |                               | - Path planners\cite{aghzal2023large}                                  |
|                      | Visual Question Answering     | - CogVLM\cite{wang2023cogvlm}                                          |
|                      |                               | - ViperGPT\cite{sur√≠s2023vipergpt}                                     |
|                      |                               | - VISPROG\cite{gupta2022visual}                                        |
|                      |                               | - MM-ReAct\cite{yang2023mmreact}                                       |
|                      |                               | - Chameleon\cite{lu2023chameleon}                                      |
|                      | Survey Papers                 | - A Survey of Large Language Models\cite{zhao2023survey}               |
| Incontext Learning   | Chain of Thought              | - Chain of Thought\cite{wei2023chainofthought}                         |
|                      |                               | - Multimodal-CoT\cite{zhang2023multimodal}                             |
|                      |                               | - Auto-CoT\cite{zhang2022automatic}                                     |
|                      | Reasoning                     | - Self-Consistency\cite{wang2023selfconsistency}                       |
|                      |                               | - Tree of Thought\cite{yao2023tree}                                    |
|                      |                               | - ReAct\cite{yao2023react}                                             |
|                      |                               | - Self-Refine\cite{madaan2023selfrefine}                               |
|                      |                               | - Plan-and-Solve\cite{wang2023planandsolve}                            |
|                      |                               | - PAL\cite{gao2023pal}                                                 |
|                      |                               | - Reasoning via Planning\cite{hao2023reasoning}                         |
|                      |                               | - Self-Ask\cite{press2023measuring}                                    |
|                      |                               | - Least-to-Most Prompting\cite{zhou2023leasttomost}                    |
|                      |                               | - Self-Polish\cite{xi2023selfpolish}                                   |
|                      |                               | - COMPLEXITY-CoT\cite{fu2023complexitybased}                           |
|                      |                               | - SuperICL\cite{xu2023small}                                           |
|                      | Automation                    | - APE\cite{zhou2023large}                                              |
| LLM for Agent        | Planning                      | - Voyager\cite{wang2023voyager}                                        |
|                      |                               | - DEPS\cite{wang2023describe}                                          |
|                      |                               | - JARVIS-1\cite{wang2023jarvis1}                                      |
|                      | Reinforcement Learning         | - Eureka\cite{ma2023eureka}                                           |
|                      |                               | - Language to Rewards\cite{yu2023language}                             |
|                      |                               | - Language Instructed Reinforcement Learning\cite{hu2023language}       |
|                      |                               | - Lafite-RL\cite{chu2023accelerating}                                  |
|                      | Survey Paper                  | - The Rise and Potential of Large Language Models\cite{xi2023rise}     |
|                      |                               | - Autonomous Agents\cite{wang2023survey}                               |
| LLM for Robots       | Multimodal Prompts             | - VIMA\cite{jiang2023vima}                                            |
|                      |                               | - Instruct2Act\cite{huang2023instruct2act}                            |
|                      |                               | - MOMA-Force\cite{yang2023momaforce}                                   |
|                      | Multimodal LLM                | - PaLM-E\cite{driess2023palme}                                         |
|                      |                               | - GATO\cite{reed2022generalist}                                        |
|                      |                               | - Flamingo\cite{alayrac2022flamingo}                                   |
|                      |                               | - Physically Grounded Vision-Language Model\cite{gao2023physically}    |
|                      |                               | - MOO\cite{stone2023openworld}                                         |
|                      | Code Generation               | - Code as Policies\cite{liang2023code}                                 |
|                      |                               | - Progprompt\cite{singh2022progprompt}                                 |
|                      |                               | - Socratic\cite{zeng2022socratic}                                     |
|                      |                               | - SMART-LLM\cite{kannan2023smartllm}                                  |
|                      |                               | - Statler\cite{yoneda2023statler}                                      |
|                      | Decomposing Task               | - SayCan\cite{ahn2022i}                                               |
|                      |                               | - Language Models as Zero-Shot Planners\cite{huang2022language}         |
|                      |                               | - SayPlan\cite{rana2023sayplan}                                       |
|                      |                               | - DOREMI\cite{guo2023doremi}                                         
